# A-Constitutional-AI-Faithfulness-Detector
This project studies faithfulness in chain-of-thought reasoning by testing whether unfaithful reasoning forms a distinct representational direction in large language models. We fine-tune models on unfaithful CoT data, use model diffing to find correlated features, and develop methods to detect or steer faithfulness for more transparent AI reasoning
